#!/usr/bin/env python3
"""
ë©´ì ‘ ë¶„ì„ í…ŒìŠ¤íŠ¸ (STT + LLM) - ê°œì„ ëœ í”Œë¡œìš°
"""

import asyncio
import json
import os
from dotenv import load_dotenv

# í™˜ê²½ë³€ìˆ˜ ë¡œë“œ
load_dotenv()

from ai.stt.service import get_stt_service
from ai.llm.service import get_llm_service
from ai.embedding.service import get_embedding_service

# ìƒ˜í”Œ ë©´ì ‘ í…ìŠ¤íŠ¸ë“¤
SAMPLE_INTERVIEWS = [
    {
        "name": "ê²½ë ¥ì§ ë°±ì—”ë“œ ê°œë°œì ë©´ì ‘",
        "text": """
        ì•ˆë…•í•˜ì„¸ìš”. ì €ëŠ” 5ë…„ê°„ ë°±ì—”ë“œ ê°œë°œì„ í•´ì˜¨ ê¹€ê°œë°œì…ë‹ˆë‹¤.

        ì´ì „ íšŒì‚¬ì¸ ë„¤ì´ë²„ì—ì„œëŠ” ì£¼ë¡œ ëŒ€ìš©ëŸ‰ API ì„œë²„ ê°œë°œì„ ë‹´ë‹¹í–ˆìŠµë‹ˆë‹¤.
        Pythonê³¼ Djangoë¥¼ ì£¼ë¡œ ì‚¬ìš©í–ˆê³ , ìµœê·¼ì—ëŠ” FastAPIë¡œ ë§ˆì´í¬ë¡œì„œë¹„ìŠ¤ ì•„í‚¤í…ì²˜ë¥¼ êµ¬ì¶•í•˜ëŠ” ê²½í—˜ë„ í–ˆìŠµë‹ˆë‹¤.

        ì €ì˜ ê°•ì ì€ ë¬¸ì œ í•´ê²° ëŠ¥ë ¥ì´ë¼ê³  ìƒê°í•©ë‹ˆë‹¤.
        ë³µì¡í•œ ì‹œìŠ¤í…œ ì´ìŠˆê°€ ë°œìƒí–ˆì„ ë•Œ ì°¨ê·¼ì°¨ê·¼ ì›ì¸ì„ ë¶„ì„í•˜ê³  í•´ê²°í•˜ëŠ” ê²ƒì„ ì¢‹ì•„í•©ë‹ˆë‹¤.

        íŒ€ì›Œí¬ë„ ì¤‘ì‹œí•©ë‹ˆë‹¤. ì½”ë“œ ë¦¬ë·°ë¥¼ í†µí•´ ë™ë£Œë“¤ê³¼ ì§€ì‹ì„ ê³µìœ í•˜ê³ ,
        ì£¼ë‹ˆì–´ ê°œë°œìë“¤ì„ ë©˜í† ë§í•˜ëŠ” ì—­í• ë„ ìì£¼ ë§¡ì•˜ìŠµë‹ˆë‹¤.

        ì•ìœ¼ë¡œëŠ” ì‹œìŠ¤í…œ ì•„í‚¤í…ì²˜ ì„¤ê³„ ì „ë¬¸ê°€ê°€ ë˜ê³  ì‹¶ìŠµë‹ˆë‹¤.
        íŠ¹íˆ í´ë¼ìš°ë“œ ë„¤ì´í‹°ë¸Œ í™˜ê²½ì—ì„œ í™•ì¥ ê°€ëŠ¥í•œ ì‹œìŠ¤í…œì„ êµ¬ì¶•í•˜ëŠ” ì¼ì— ê´€ì‹¬ì´ ë§ìŠµë‹ˆë‹¤.

        ì—…ë¬´ í™˜ê²½ì€ ììœ¨ì ì´ê³  ìˆ˜í‰ì ì¸ ì¡°ì§ë¬¸í™”ë¥¼ ì„ í˜¸í•©ë‹ˆë‹¤.
        ê¸°ìˆ ì  ë„ì „ì´ ìˆëŠ” í”„ë¡œì íŠ¸ì—ì„œ ì¼í•˜ê³  ì‹¶ê³ , ì›ê²©ê·¼ë¬´ê°€ ê°€ëŠ¥í•œ í™˜ê²½ì´ë©´ ë” ì¢‹ê² ìŠµë‹ˆë‹¤.
        """
    },
    {
        "name": "ì‹ ì… í”„ë¡ íŠ¸ì—”ë“œ ê°œë°œì ë©´ì ‘",
        "text": """
        ì•ˆë…•í•˜ì„¸ìš”. ì»´í“¨í„°ê³µí•™ê³¼ë¥¼ ì¡¸ì—…í•œ ì‹ ì… ê°œë°œì ë°•ì‹ ì…ì…ë‹ˆë‹¤.

        ëŒ€í•™êµì—ì„œ Reactì™€ JavaScriptë¥¼ ì£¼ë¡œ ê³µë¶€í–ˆê³ ,
        ì¡¸ì—… í”„ë¡œì íŠ¸ë¡œ ì‹¤ì‹œê°„ ì±„íŒ… ì• í”Œë¦¬ì¼€ì´ì…˜ì„ ê°œë°œí–ˆìŠµë‹ˆë‹¤.

        ê°œì¸ì ìœ¼ë¡œ ì‚¬ìš©ì ê²½í—˜ì— ëŒ€í•´ ê´€ì‹¬ì´ ë§ìŠµë‹ˆë‹¤.
        ë‹¨ìˆœíˆ ê¸°ëŠ¥ì´ ì‘ë™í•˜ëŠ” ê²ƒì„ ë„˜ì–´ì„œ, ì‚¬ìš©ìê°€ í¸ë¦¬í•˜ê³  ì¦ê²ê²Œ ì‚¬ìš©í•  ìˆ˜ ìˆëŠ” ì¸í„°í˜ì´ìŠ¤ë¥¼ ë§Œë“¤ê³  ì‹¶ìŠµë‹ˆë‹¤.

        ì €ëŠ” ê¼¼ê¼¼í•œ ì„±ê²©ì´ê³  ìƒˆë¡œìš´ ê²ƒì„ ë°°ìš°ëŠ” ê²ƒì„ ì¢‹ì•„í•©ë‹ˆë‹¤.
        ìµœê·¼ì—ëŠ” TypeScriptì™€ Next.jsë¥¼ ë…í•™ìœ¼ë¡œ ê³µë¶€í•˜ê³  ìˆìŠµë‹ˆë‹¤.

        íŒ€ í”„ë¡œì íŠ¸ì—ì„œëŠ” ì£¼ë¡œ ì»¤ë®¤ë‹ˆì¼€ì´ì…˜ ì—­í• ì„ ë§¡ì•˜ìŠµë‹ˆë‹¤.
        íŒ€ì›ë“¤ì˜ ì˜ê²¬ì„ ì˜ ë“¤ì–´ì£¼ê³  ì¡°ìœ¨í•˜ëŠ” í¸ì…ë‹ˆë‹¤.

        ëª©í‘œëŠ” í’€ìŠ¤íƒ ê°œë°œìê°€ ë˜ëŠ” ê²ƒì…ë‹ˆë‹¤.
        ì§€ê¸ˆì€ í”„ë¡ íŠ¸ì—”ë“œì— ì§‘ì¤‘í•˜ê³  ìˆì§€ë§Œ, ë‚˜ì¤‘ì—ëŠ” ë°±ì—”ë“œë„ í•  ìˆ˜ ìˆëŠ” ê°œë°œìê°€ ë˜ê³  ì‹¶ìŠµë‹ˆë‹¤.

        ë¹ ë¥´ê²Œ ì„±ì¥í•  ìˆ˜ ìˆëŠ” ìŠ¤íƒ€íŠ¸ì—… í™˜ê²½ì—ì„œ ì¼í•˜ê³  ì‹¶ìŠµë‹ˆë‹¤.
        ë©˜í† ë§ì„ ë°›ì„ ìˆ˜ ìˆê³ , ë‹¤ì–‘í•œ ê²½í—˜ì„ ìŒ“ì„ ìˆ˜ ìˆëŠ” ê³³ì´ë©´ ì¢‹ê² ìŠµë‹ˆë‹¤.
        """
    },
    {
        "name": "ë°ì´í„° ì‚¬ì´ì–¸í‹°ìŠ¤íŠ¸ ë©´ì ‘",
        "text": """
        ì•ˆë…•í•˜ì„¸ìš”. ë°ì´í„° ë¶„ì„ ë¶„ì•¼ì—ì„œ 3ë…„ê°„ ì¼í•´ì˜¨ ì´ë°ì´í„°ì…ë‹ˆë‹¤.

        ì´ì „ íšŒì‚¬ì—ì„œëŠ” ì£¼ë¡œ ê³ ê° í–‰ë™ ë¶„ì„ê³¼ ì¶”ì²œ ì‹œìŠ¤í…œ ê°œë°œì„ ë‹´ë‹¹í–ˆìŠµë‹ˆë‹¤.
        Pythonê³¼ pandas, scikit-learnì„ ì£¼ë¡œ ì‚¬ìš©í–ˆê³ ,
        ìµœê·¼ì—ëŠ” TensorFlowì™€ PyTorchë¡œ ë”¥ëŸ¬ë‹ ëª¨ë¸ë§ë„ í•˜ê³  ìˆìŠµë‹ˆë‹¤.

        ì €ì˜ ê°•ì ì€ ë°ì´í„°ì—ì„œ ì˜ë¯¸ìˆëŠ” ì¸ì‚¬ì´íŠ¸ë¥¼ ì°¾ì•„ë‚´ëŠ” ëŠ¥ë ¥ì…ë‹ˆë‹¤.
        ë³µì¡í•œ ë°ì´í„°ë¥¼ ì‹œê°í™”í•´ì„œ ë¹„ì¦ˆë‹ˆìŠ¤ íŒ€ì´ ì´í•´í•˜ê¸° ì‰½ê²Œ ì „ë‹¬í•˜ëŠ” ê²ƒë„ ì˜í•©ë‹ˆë‹¤.

        ë˜í•œ ë¹„ì¦ˆë‹ˆìŠ¤ ê°ê°ë„ ê°–ì¶”ë ¤ê³  ë…¸ë ¥í•©ë‹ˆë‹¤.
        ë‹¨ìˆœíˆ ëª¨ë¸ ì„±ëŠ¥ë§Œ ë†’ì´ëŠ” ê²ƒì´ ì•„ë‹ˆë¼, ì‹¤ì œ ë¹„ì¦ˆë‹ˆìŠ¤ ê°€ì¹˜ë¥¼ ë§Œë“¤ì–´ë‚´ëŠ” ê²ƒì´ ì¤‘ìš”í•˜ë‹¤ê³  ìƒê°í•©ë‹ˆë‹¤.

        ì˜ì‚¬ì†Œí†µ ëŠ¥ë ¥ë„ ì¤‘ìš”í•˜ê²Œ ìƒê°í•©ë‹ˆë‹¤.
        ê°œë°œíŒ€, ê¸°íšíŒ€ê³¼ í˜‘ì—…í•  ë•Œ ì„œë¡œ ë‹¤ë¥¸ ê´€ì ì„ ì´í•´í•˜ê³  ì¡°ìœ¨í•˜ëŠ” ì—­í• ì„ ìì£¼ í–ˆìŠµë‹ˆë‹¤.

        ì•ìœ¼ë¡œëŠ” MLOps ë¶„ì•¼ë¡œ í™•ì¥í•˜ê³  ì‹¶ìŠµë‹ˆë‹¤.
        ëª¨ë¸ì„ ê°œë°œí•˜ëŠ” ê²ƒë¿ë§Œ ì•„ë‹ˆë¼ í”„ë¡œë•ì…˜ í™˜ê²½ì— ì•ˆì •ì ìœ¼ë¡œ ë°°í¬í•˜ê³  ìš´ì˜í•˜ëŠ” ì „ ê³¼ì •ì„ ê²½í—˜í•´ë³´ê³  ì‹¶ìŠµë‹ˆë‹¤.

        ë°ì´í„° ì¤‘ì‹¬ì˜ ì˜ì‚¬ê²°ì •ì„ í•˜ëŠ” íšŒì‚¬ì—ì„œ ì¼í•˜ê³  ì‹¶ìŠµë‹ˆë‹¤.
        AI/ML ê¸°ìˆ ì´ í•µì‹¬ì¸ í”„ë¡œë•íŠ¸ë¥¼ ë§Œë“œëŠ” íŒ€ì´ë©´ ë”ìš± ì¢‹ê² ìŠµë‹ˆë‹¤.
        """
    }
]

# ë”ë¯¸ DB í”„ë¡œí•„ ë°ì´í„°
DUMMY_DB_PROFILES = [
    {
        "user_id": 1,
        "profile": {"name": "ê¹€ê°œë°œ", "birth_date": "1990-01-01"},
        "educations": [
            {
                "school_name": "ì„œìš¸ëŒ€í•™êµ",
                "major": "ì»´í“¨í„°ê³µí•™",
                "status": "ì¡¸ì—…",
                "start_ym": "2012-03",
                "end_ym": "2016-02"
            }
        ],
        "experiences": [
            {
                "company_name": "ë„¤ì´ë²„",
                "title": "ë°±ì—”ë“œ ê°œë°œì",
                "start_ym": "2016-03",
                "end_ym": "2021-12",
                "summary": "ëŒ€ìš©ëŸ‰ API ì„œë²„ ê°œë°œ ë° ìš´ì˜"
            },
            {
                "company_name": "í˜„ì¬íšŒì‚¬",
                "title": "ì‹œë‹ˆì–´ ë°±ì—”ë“œ ê°œë°œì",
                "start_ym": "2022-01",
                "end_ym": None,
                "summary": "ë§ˆì´í¬ë¡œì„œë¹„ìŠ¤ ì•„í‚¤í…ì²˜ êµ¬ì¶•"
            }
        ],
        "activities": [
            {
                "name": "ì˜¤í”ˆì†ŒìŠ¤ ê¸°ì—¬",
                "category": "ê°œë°œ",
                "description": "Django, FastAPI ì˜¤í”ˆì†ŒìŠ¤ í”„ë¡œì íŠ¸ ê¸°ì—¬"
            }
        ],
        "certifications": [
            {
                "name": "AWS Solutions Architect",
                "acquired_ym": "2020-06"
            }
        ]
    },
    {
        "user_id": 2,
        "profile": {"name": "ë°•ì‹ ì…", "birth_date": "1998-05-15"},
        "educations": [
            {
                "school_name": "ì—°ì„¸ëŒ€í•™êµ",
                "major": "ì»´í“¨í„°ê³µí•™",
                "status": "ì¡¸ì—…",
                "start_ym": "2018-03",
                "end_ym": "2024-02"
            }
        ],
        "experiences": [],  # ì‹ ì…ì´ë¯€ë¡œ ê²½ë ¥ ì—†ìŒ
        "activities": [
            {
                "name": "ì¡¸ì—… í”„ë¡œì íŠ¸",
                "category": "í”„ë¡œì íŠ¸",
                "description": "React ê¸°ë°˜ ì‹¤ì‹œê°„ ì±„íŒ… ì• í”Œë¦¬ì¼€ì´ì…˜"
            },
            {
                "name": "í”„ë¡œê·¸ë˜ë° ë™ì•„ë¦¬",
                "category": "ë™ì•„ë¦¬",
                "description": "ì›¹ ê°œë°œ ìŠ¤í„°ë”” ë¦¬ë”"
            }
        ],
        "certifications": []
    }
]

def test_interview_analysis_only(interview_data):
    """ë©´ì ‘ ë¶„ì„ë§Œ í…ŒìŠ¤íŠ¸ (STT ì œì™¸, í…ìŠ¤íŠ¸ ì§ì ‘ ì‚¬ìš©)"""
    print(f"\nğŸ¤ {interview_data['name']} ë¶„ì„ ì¤‘...")
    print("=" * 50)

    try:
        # LLMìœ¼ë¡œ ë©´ì ‘ ë‚´ìš© ë¶„ì„
        llm_service = get_llm_service()

        # í”„ë¡¬í”„íŠ¸ ëª¨ë“ˆì—ì„œ ê°€ì ¸ì˜¤ê¸°
        from ai.llm.prompts import build_interview_analysis_messages

        messages = build_interview_analysis_messages(interview_data['text'])

        response = llm_service.generate_completion(messages=messages, temperature=0.7)

        print("âœ… ë©´ì ‘ ë¶„ì„ ì™„ë£Œ!")
        print(f"ì‘ë‹µ ê¸¸ì´: {len(response.content)} ê¸€ì")
        print(f"ì‚¬ìš© ëª¨ë¸: {response.model}")

        # JSON íŒŒì‹± ì‹œë„ (ê°œì„ ëœ íŒŒì‹± ë¡œì§)
        from ai.llm.utils import parse_llm_json_response, format_list_display, format_text_display

        analysis = parse_llm_json_response(response.content)

        if analysis:
            print("\nğŸ“Š êµ¬ì¡°í™”ëœ ë¶„ì„ ê²°ê³¼:")
            for key, value in analysis.items():
                if isinstance(value, list):
                    print(f"  {key}: {format_list_display(value)}")
                else:
                    print(f"  {key}: {format_text_display(str(value), 80)}")

            return analysis
        else:
            print("âš ï¸  JSON íŒŒì‹± ì‹¤íŒ¨, ì›ë³¸ í…ìŠ¤íŠ¸ ì‘ë‹µ:")
            print(response.content[:300] + "...")
            return {"raw_response": response.content}

    except Exception as e:
        print(f"âŒ ë©´ì ‘ ë¶„ì„ ì‹¤íŒ¨: {e}")
        return None

def test_db_interview_integration(db_profile, interview_analysis):
    """DB í”„ë¡œí•„ + ë©´ì ‘ ë¶„ì„ í†µí•© í…ŒìŠ¤íŠ¸"""
    print(f"\nğŸ”— DB + ë©´ì ‘ í†µí•© ë¶„ì„ í…ŒìŠ¤íŠ¸")
    print("=" * 50)

    try:
        llm_service = get_llm_service()

        # í”„ë¡¬í”„íŠ¸ ëª¨ë“ˆì—ì„œ ê°€ì ¸ì˜¤ê¸°
        from ai.llm.prompts import build_integration_messages

        messages = build_integration_messages(db_profile, interview_analysis)
        response = llm_service.generate_completion(messages=messages, temperature=0.5)

        print("âœ… í†µí•© ë¶„ì„ ì™„ë£Œ!")

        # JSON íŒŒì‹± ì‹œë„ (ê°œì„ ëœ íŒŒì‹± ë¡œì§)
        from ai.llm.utils import parse_llm_json_response, format_list_display, format_text_display

        integrated_profile = parse_llm_json_response(response.content)

        if integrated_profile:
            print("\nğŸ¯ ìµœì¢… í†µí•© í”„ë¡œí•„:")
            for key, value in integrated_profile.items():
                if isinstance(value, list):
                    print(f"  {key}: {format_list_display(value, 4)}")
                else:
                    print(f"  {key}: {format_text_display(str(value), 100)}")

            return integrated_profile
        else:
            print("âš ï¸  JSON íŒŒì‹± ì‹¤íŒ¨, ì›ë³¸ ì‘ë‹µ:")
            print(response.content[:400] + "...")
            return {"raw_response": response.content}

    except Exception as e:
        print(f"âŒ í†µí•© ë¶„ì„ ì‹¤íŒ¨: {e}")
        return None

def test_embedding_generation(integrated_profile):
    """í†µí•© í”„ë¡œí•„ë¡œ ì„ë² ë”© ë²¡í„° ìƒì„± í…ŒìŠ¤íŠ¸"""
    print(f"\nğŸ”¢ ì„ë² ë”© ë²¡í„° ìƒì„± í…ŒìŠ¤íŠ¸")
    print("=" * 50)

    try:
        embedding_service = get_embedding_service()

        # í”„ë¡œí•„ì—ì„œ í…ìŠ¤íŠ¸ ì¶”ì¶œ (ì•ˆì „í•˜ê²Œ)
        from ai.llm.utils import safe_get_from_dict, format_text_display

        preferences = safe_get_from_dict(integrated_profile, 'work_preferences', 'ì—…ë¬´ í™˜ê²½ ì„ í˜¸ì‚¬í•­ ì—†ìŒ')
        technical_skills = safe_get_from_dict(integrated_profile, 'technical_skills', [])
        soft_skills = safe_get_from_dict(integrated_profile, 'soft_skills', [])

        skills = ', '.join(technical_skills + soft_skills)
        if not skills.strip():
            skills = 'ìŠ¤í‚¬ ì •ë³´ ì—†ìŒ'

        print(f"ì„ í˜¸ì‚¬í•­: {format_text_display(preferences, 100)}")
        print(f"ìŠ¤í‚¬: {format_text_display(skills, 100)}")

        # ì„ë² ë”© ë²¡í„° ìƒì„±
        candidate_vector = embedding_service.create_applicant_vector(
            preferences=preferences,
            skills=skills
        )

        print("âœ… ì„ë² ë”© ë²¡í„° ìƒì„± ì™„ë£Œ!")
        print(f"ë²¡í„° ì°¨ì›: {candidate_vector.dimension}")
        print(f"ì‚¬ìš© ëª¨ë¸: {candidate_vector.model}")
        print(f"ì¼ë°˜ ë²¡í„° í¬ê¸°: {len(candidate_vector.general_vector)}")
        print(f"ìŠ¤í‚¬ ë²¡í„° í¬ê¸°: {len(candidate_vector.skills_vector)}")
        print(f"í†µí•© ë²¡í„° í¬ê¸°: {len(candidate_vector.combined_vector)}")

        return candidate_vector

    except Exception as e:
        print(f"âŒ ì„ë² ë”© ìƒì„± ì‹¤íŒ¨: {e}")
        return None

def main():
    """ë©”ì¸ í…ŒìŠ¤íŠ¸ ì‹¤í–‰"""
    print("ğŸš€ ê°œì„ ëœ ë©´ì ‘ ë¶„ì„ í”Œë¡œìš° í…ŒìŠ¤íŠ¸")
    print("=" * 60)

    # LLM ì„œë¹„ìŠ¤ ìƒíƒœ í™•ì¸
    llm_service = get_llm_service()
    health = llm_service.health_check()

    if health.get('status') != 'healthy':
        print("âŒ LLM ì„œë¹„ìŠ¤ê°€ ì •ìƒì ì´ì§€ ì•ŠìŠµë‹ˆë‹¤. API í‚¤ë¥¼ í™•ì¸í•´ì£¼ì„¸ìš”.")
        print(f"ì‹¤ì œ í—¬ìŠ¤ì²´í¬ ê²°ê³¼: {health}")
        return

    # ì„ë² ë”© ì„œë¹„ìŠ¤ ìƒíƒœ í™•ì¸
    embedding_service = get_embedding_service()
    embedding_health = embedding_service.health_check()
    print(f"ğŸ“Š ì„œë¹„ìŠ¤ ìƒíƒœ - LLM: {health.get('status')}, ì„ë² ë”©: {embedding_health.service_status}")

    # ê° ìƒ˜í”Œì— ëŒ€í•´ ì „ì²´ í”Œë¡œìš° í…ŒìŠ¤íŠ¸
    for i, (interview, db_profile) in enumerate(zip(SAMPLE_INTERVIEWS, DUMMY_DB_PROFILES)):
        print(f"\n{'='*20} í…ŒìŠ¤íŠ¸ ì¼€ì´ìŠ¤ {i+1} {'='*20}")

        # 1. ë©´ì ‘ ë¶„ì„
        interview_analysis = test_interview_analysis_only(interview)
        if not interview_analysis:
            continue

        # 2. DB + ë©´ì ‘ í†µí•©
        integrated_profile = test_db_interview_integration(db_profile, interview_analysis)
        if not integrated_profile:
            continue

        # 3. ì„ë² ë”© ë²¡í„° ìƒì„±
        candidate_vector = test_embedding_generation(integrated_profile)

        print(f"\nâœ… ì¼€ì´ìŠ¤ {i+1} ì™„ë£Œ!")

    print("\n" + "=" * 60)
    print("ğŸ‰ ì „ì²´ í…ŒìŠ¤íŠ¸ ì™„ë£Œ!")
    print("\nğŸ¯ ê²°ê³¼ ìš”ì•½:")
    print("- ë©´ì ‘ ë‚´ìš©ë§Œ LLM ë¶„ì„ (STT ì œì™¸)")
    print("- DB ë°ì´í„°ëŠ” êµ¬ì¡°í™”ëœ ìƒíƒœë¡œ ì§ì ‘ ì‚¬ìš©")
    print("- ë‘ ê²°ê³¼ë¥¼ LLMìœ¼ë¡œ í†µí•©")
    print("- ìµœì¢… í”„ë¡œí•„ë¡œ ì„ë² ë”© ë²¡í„° ìƒì„±")

if __name__ == "__main__":
    main()